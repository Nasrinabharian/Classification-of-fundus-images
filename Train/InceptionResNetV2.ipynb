{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "518f247d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34af46f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ID  Normal  Diabetes  Glaucoma  Cataract  AMD  Hypertension  \\\n",
      "0   0_left.jpg       0         0         0         1    0             0   \n",
      "1  0_right.jpg       1         0         0         0    0             0   \n",
      "2   1_left.jpg       1         0         0         0    0             0   \n",
      "3  1_right.jpg       1         0         0         0    0             0   \n",
      "4   2_left.jpg       0         1         0         0    0             0   \n",
      "\n",
      "   Myopia  Others  Total  \n",
      "0       0       0      1  \n",
      "1       0       0      1  \n",
      "2       0       0      1  \n",
      "3       0       0      1  \n",
      "4       0       1      2  \n",
      "Index(['ID', 'Normal', 'Diabetes', 'Glaucoma', 'Cataract', 'AMD',\n",
      "       'Hypertension', 'Myopia', 'Others', 'Total'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "image_directory = r'D:\\Projects\\ODIR\\ODIRCODE\\PreprocessingCodes\\Input_224/'\n",
    "\n",
    "\n",
    "#Now let us read metadata to get our Y values (multiple lables)\n",
    "df = pd.read_csv(r'D:\\Projects\\ODIR\\ODIRCODE\\Prepro\\ground_truth\\all\\odirALL.csv')    \n",
    "print(df.head())     # printing first five rows of the file\n",
    "print(df.columns)\n",
    "\n",
    "df = df.iloc[:23000]  #Loading only first 1000 datapoints for memory reasons \n",
    "#Need to read images using the tag from metadata.\n",
    "#Otherwise, if read directly from the folder then images may not correspond to \n",
    "#the metadata from the csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa7e68bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 22032/22032 [01:27<00:00, 251.02it/s]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "SIZE = 224\n",
    "X_dataset = []  \n",
    "for i in tqdm(range(df.shape[0])):\n",
    "    img = load_img(image_directory +df['ID'][i], target_size=(SIZE,SIZE,3))   \n",
    "    img = img_to_array(img)\n",
    "    img = img/255.\n",
    "    X_dataset.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7de2c79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e95a5a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(X[21000], interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a35b6605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268_left.jpg\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "print(df['ID'][500])  #King Kong\n",
    "\n",
    "print(df['Total'][500])  #Tagged as multiple Genres.\n",
    "\n",
    "#Id and Genre are not labels to be trained. So drop them from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d493ebce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(df.drop(['ID', 'Total'], axis=1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=20, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac80687d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.7/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "219062272/219055592 [==============================] - 39s 0us/step\n"
     ]
    }
   ],
   "source": [
    "#from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.layers import Flatten\n",
    "checkpoint1 = ModelCheckpoint(filepath=r'D:\\Projects\\ODIR\\ODIRCODE\\bestres\\IncResV2\\my_best_model.epoch{epoch:03d}-loss{val_loss:.2f}.hdf5', \n",
    "                             monitor='val_loss',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True,\n",
    "                             mode='min')\n",
    "checkpoint2 = ModelCheckpoint(filepath=r'D:\\Projects\\ODIR\\ODIRCODE\\bestres\\IncResV2\\my_best_model.epoch{epoch:03d}-acc{val_accuracy:.2f}.hdf5', \n",
    "                             monitor='val_accuracy',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True,\n",
    "                             mode='max')\n",
    "\n",
    "callbacks = [checkpoint1,checkpoint2]\n",
    "IncResV2 = tf.keras.applications.InceptionResNetV2(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=(224,224,3),\n",
    "    pooling=None,\n",
    "    classes=8\n",
    ")\n",
    "\n",
    "  #  classifier_activation=\"softmax\",\n",
    " #   **kwargs\n",
    "#res=tf.keras.applications.resnet.ResNet101(include_top=False,weights='imagenet',input_tensor=None,\n",
    "   # input_shape=(224,224,3),\n",
    " #   pooling=None,\n",
    "  #  classes=8)\n",
    "\n",
    "#inc=InceptionV3(input_shape=(200,200,3),weights='imagenet', include_top=False)\n",
    "for i in IncResV2.layers:\n",
    "    i.trainable=True\n",
    "x=Flatten()(IncResV2.output)\n",
    "pred=Dense(8,activation='sigmoid')(x)\n",
    "model=Model(inputs=IncResV2.input,outputs=pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "794037f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 111, 111, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 111, 111, 32) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 111, 111, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 109, 109, 32) 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 109, 109, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 109, 109, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 109, 109, 64) 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 109, 109, 64) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 109, 109, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 54, 54, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 54, 54, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 54, 54, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 54, 54, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 52, 52, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 52, 52, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 52, 52, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 25, 25, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 25, 25, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 25, 25, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 25, 25, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 25, 25, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 25, 25, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 25, 25, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 25, 25, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 25, 25, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 25, 25, 96)   18432       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 25, 25, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 25, 25, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 25, 25, 64)   12288       average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 25, 25, 96)   288         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 25, 25, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 25, 25, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 25, 25, 64)   192         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 25, 25, 96)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 25, 25, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 25, 25, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 25, 25, 64)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed_5b (Concatenate)          (None, 25, 25, 320)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 25, 25, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 25, 25, 32)   96          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 25, 25, 32)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 25, 25, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 25, 25, 48)   13824       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 25, 25, 32)   96          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 25, 25, 48)   144         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 25, 25, 32)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 25, 25, 48)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 25, 25, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 25, 25, 32)   9216        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 25, 25, 64)   27648       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 25, 25, 32)   96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 25, 25, 32)   96          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 25, 25, 64)   192         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 25, 25, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 25, 25, 32)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 25, 25, 64)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_1 (Lambda)              (None, 25, 25, 320)  0           mixed_5b[0][0]                   \n",
      "                                                                 block35_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_ac (Activation)       (None, 25, 25, 320)  0           block35_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 25, 25, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 25, 25, 32)   96          conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 25, 25, 32)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 25, 25, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 25, 25, 48)   13824       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 25, 25, 32)   96          conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 25, 25, 48)   144         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 25, 25, 32)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 25, 25, 48)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 25, 25, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 25, 25, 32)   9216        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 25, 25, 64)   27648       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 25, 25, 32)   96          conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 25, 25, 32)   96          conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 25, 25, 64)   192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 25, 25, 32)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 25, 25, 32)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 25, 25, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_18[0][0]              \n",
      "                                                                 activation_20[0][0]              \n",
      "                                                                 activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_2 (Lambda)              (None, 25, 25, 320)  0           block35_1_ac[0][0]               \n",
      "                                                                 block35_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_ac (Activation)       (None, 25, 25, 320)  0           block35_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 25, 25, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 25, 25, 32)   96          conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 25, 25, 32)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 25, 25, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 25, 25, 48)   13824       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 25, 25, 32)   96          conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 25, 25, 48)   144         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 25, 25, 32)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 25, 25, 48)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 25, 25, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 25, 25, 32)   9216        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 25, 25, 64)   27648       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 25, 25, 32)   96          conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 25, 25, 32)   96          conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 25, 25, 64)   192         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 25, 25, 32)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 25, 25, 32)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 25, 25, 64)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_24[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_3 (Lambda)              (None, 25, 25, 320)  0           block35_2_ac[0][0]               \n",
      "                                                                 block35_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_ac (Activation)       (None, 25, 25, 320)  0           block35_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 25, 25, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 25, 25, 32)   96          conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 25, 25, 32)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 25, 25, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 25, 25, 48)   13824       activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 25, 25, 32)   96          conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 25, 25, 48)   144         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 25, 25, 32)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 25, 25, 48)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 25, 25, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 25, 25, 32)   9216        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 25, 25, 64)   27648       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 25, 25, 32)   96          conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 25, 25, 32)   96          conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 25, 25, 64)   192         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 25, 25, 32)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 25, 25, 32)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 25, 25, 64)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_30[0][0]              \n",
      "                                                                 activation_32[0][0]              \n",
      "                                                                 activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_4 (Lambda)              (None, 25, 25, 320)  0           block35_3_ac[0][0]               \n",
      "                                                                 block35_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_ac (Activation)       (None, 25, 25, 320)  0           block35_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 25, 25, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 25, 25, 32)   96          conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 25, 25, 32)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 25, 25, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 25, 25, 48)   13824       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 25, 25, 32)   96          conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 25, 25, 48)   144         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 25, 25, 32)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 25, 25, 48)   0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 25, 25, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 25, 25, 32)   9216        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 25, 25, 64)   27648       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 25, 25, 32)   96          conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 25, 25, 32)   96          conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 25, 25, 64)   192         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 25, 25, 32)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 25, 25, 32)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 25, 25, 64)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_36[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_5 (Lambda)              (None, 25, 25, 320)  0           block35_4_ac[0][0]               \n",
      "                                                                 block35_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_ac (Activation)       (None, 25, 25, 320)  0           block35_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 25, 25, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 25, 25, 32)   96          conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 25, 25, 32)   0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 25, 25, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 25, 25, 48)   13824       activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 25, 25, 32)   96          conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 25, 25, 48)   144         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 25, 25, 32)   0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 25, 25, 48)   0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 25, 25, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 25, 25, 32)   9216        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 25, 25, 64)   27648       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 25, 25, 32)   96          conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 25, 25, 32)   96          conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 25, 25, 64)   192         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 25, 25, 32)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 25, 25, 32)   0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 25, 25, 64)   0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_42[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_6 (Lambda)              (None, 25, 25, 320)  0           block35_5_ac[0][0]               \n",
      "                                                                 block35_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_ac (Activation)       (None, 25, 25, 320)  0           block35_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 25, 25, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 25, 25, 32)   96          conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 25, 25, 32)   0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 25, 25, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 25, 25, 48)   13824       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 25, 25, 32)   96          conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 25, 25, 48)   144         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 25, 25, 32)   0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 25, 25, 48)   0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 25, 25, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 25, 25, 32)   9216        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 25, 25, 64)   27648       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 25, 25, 32)   96          conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 25, 25, 32)   96          conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 25, 25, 64)   192         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 25, 25, 32)   0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 25, 25, 32)   0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 25, 25, 64)   0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_48[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_7 (Lambda)              (None, 25, 25, 320)  0           block35_6_ac[0][0]               \n",
      "                                                                 block35_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_ac (Activation)       (None, 25, 25, 320)  0           block35_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 25, 25, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 25, 25, 32)   96          conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 25, 25, 32)   0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 25, 25, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 25, 25, 48)   13824       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 25, 25, 32)   96          conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 25, 25, 48)   144         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 25, 25, 32)   0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 25, 25, 48)   0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 25, 25, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 25, 25, 32)   9216        activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 25, 25, 64)   27648       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 25, 25, 32)   96          conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 25, 25, 32)   96          conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 25, 25, 64)   192         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 25, 25, 32)   0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 25, 25, 32)   0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 25, 25, 64)   0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_54[0][0]              \n",
      "                                                                 activation_56[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_8 (Lambda)              (None, 25, 25, 320)  0           block35_7_ac[0][0]               \n",
      "                                                                 block35_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_ac (Activation)       (None, 25, 25, 320)  0           block35_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 25, 25, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 25, 25, 32)   96          conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 25, 25, 32)   0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 25, 25, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 25, 25, 48)   13824       activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 25, 25, 32)   96          conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 25, 25, 48)   144         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 25, 25, 32)   0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 25, 25, 48)   0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 25, 25, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 25, 25, 32)   9216        activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 25, 25, 64)   27648       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 25, 25, 32)   96          conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 25, 25, 32)   96          conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 25, 25, 64)   192         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 25, 25, 32)   0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 25, 25, 32)   0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 25, 25, 64)   0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_60[0][0]              \n",
      "                                                                 activation_62[0][0]              \n",
      "                                                                 activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_9 (Lambda)              (None, 25, 25, 320)  0           block35_8_ac[0][0]               \n",
      "                                                                 block35_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_ac (Activation)       (None, 25, 25, 320)  0           block35_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 25, 25, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 25, 25, 32)   96          conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 25, 25, 32)   0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 25, 25, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 25, 25, 48)   13824       activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 25, 25, 32)   96          conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 25, 25, 48)   144         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 25, 25, 32)   0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 25, 25, 48)   0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 25, 25, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 25, 25, 32)   9216        activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 25, 25, 64)   27648       activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 25, 25, 32)   96          conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 25, 25, 32)   96          conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 25, 25, 64)   192         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 25, 25, 32)   0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 25, 25, 32)   0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 25, 25, 64)   0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_mixed (Concatenate)  (None, 25, 25, 128)  0           activation_66[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_conv (Conv2D)        (None, 25, 25, 320)  41280       block35_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block35_10 (Lambda)             (None, 25, 25, 320)  0           block35_9_ac[0][0]               \n",
      "                                                                 block35_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_ac (Activation)      (None, 25, 25, 320)  0           block35_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 25, 25, 256)  81920       block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 25, 25, 256)  768         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 25, 25, 256)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 25, 25, 256)  589824      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 25, 25, 256)  768         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 25, 25, 256)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 12, 12, 384)  1105920     block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 12, 12, 384)  884736      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 12, 12, 384)  1152        conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 12, 12, 384)  1152        conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 12, 12, 384)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 12, 12, 384)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 12, 12, 320)  0           block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_6a (Concatenate)          (None, 12, 12, 1088) 0           activation_72[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 12, 12, 128)  139264      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 12, 12, 128)  384         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 12, 12, 128)  0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 12, 12, 160)  143360      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 12, 12, 160)  480         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 12, 12, 160)  0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 12, 12, 192)  208896      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 12, 12, 192)  215040      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 12, 12, 192)  576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 12, 12, 192)  576         conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 12, 12, 192)  0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 12, 12, 192)  0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_76[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_1 (Lambda)              (None, 12, 12, 1088) 0           mixed_6a[0][0]                   \n",
      "                                                                 block17_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_ac (Activation)       (None, 12, 12, 1088) 0           block17_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 12, 12, 128)  139264      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 12, 12, 128)  384         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 12, 12, 128)  0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 12, 12, 160)  143360      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 12, 12, 160)  480         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 12, 12, 160)  0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 12, 12, 192)  208896      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 12, 12, 192)  215040      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 12, 12, 192)  576         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 12, 12, 192)  576         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 12, 12, 192)  0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 12, 12, 192)  0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_80[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_2 (Lambda)              (None, 12, 12, 1088) 0           block17_1_ac[0][0]               \n",
      "                                                                 block17_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_ac (Activation)       (None, 12, 12, 1088) 0           block17_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 12, 12, 128)  139264      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 12, 12, 128)  384         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 12, 12, 128)  0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 12, 12, 160)  143360      activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 12, 12, 160)  480         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 12, 12, 160)  0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 12, 12, 192)  208896      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 12, 12, 192)  215040      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 12, 12, 192)  576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 12, 12, 192)  576         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 12, 12, 192)  0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 12, 12, 192)  0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_84[0][0]              \n",
      "                                                                 activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_3 (Lambda)              (None, 12, 12, 1088) 0           block17_2_ac[0][0]               \n",
      "                                                                 block17_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_ac (Activation)       (None, 12, 12, 1088) 0           block17_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 12, 12, 128)  139264      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 12, 12, 128)  384         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 12, 12, 128)  0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 12, 12, 160)  143360      activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 12, 12, 160)  480         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 12, 12, 160)  0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 12, 12, 192)  208896      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 12, 12, 192)  215040      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 12, 12, 192)  576         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 12, 12, 192)  576         conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 12, 12, 192)  0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 12, 12, 192)  0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_88[0][0]              \n",
      "                                                                 activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_4 (Lambda)              (None, 12, 12, 1088) 0           block17_3_ac[0][0]               \n",
      "                                                                 block17_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_ac (Activation)       (None, 12, 12, 1088) 0           block17_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 12, 12, 128)  139264      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 12, 12, 128)  384         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 12, 12, 128)  0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 12, 12, 160)  143360      activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 12, 12, 160)  480         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 12, 12, 160)  0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 12, 12, 192)  208896      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 12, 12, 192)  215040      activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 12, 12, 192)  576         conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 12, 12, 192)  576         conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 12, 12, 192)  0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 12, 12, 192)  0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_92[0][0]              \n",
      "                                                                 activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_5 (Lambda)              (None, 12, 12, 1088) 0           block17_4_ac[0][0]               \n",
      "                                                                 block17_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_ac (Activation)       (None, 12, 12, 1088) 0           block17_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 12, 12, 128)  139264      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 12, 12, 128)  384         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 12, 12, 128)  0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 12, 12, 160)  143360      activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 12, 12, 160)  480         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 12, 12, 160)  0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 12, 12, 192)  208896      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 12, 12, 192)  215040      activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 12, 12, 192)  576         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 12, 12, 192)  576         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 12, 12, 192)  0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 12, 12, 192)  0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_96[0][0]              \n",
      "                                                                 activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_6 (Lambda)              (None, 12, 12, 1088) 0           block17_5_ac[0][0]               \n",
      "                                                                 block17_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_ac (Activation)       (None, 12, 12, 1088) 0           block17_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 12, 12, 128)  139264      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 12, 12, 128)  384         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 12, 12, 128)  0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 12, 12, 160)  143360      activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 12, 12, 160)  480         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 12, 12, 160)  0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 12, 12, 192)  208896      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 12, 12, 192)  215040      activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 12, 12, 192)  576         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 12, 12, 192)  576         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 12, 12, 192)  0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 12, 12, 192)  0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_100[0][0]             \n",
      "                                                                 activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_7 (Lambda)              (None, 12, 12, 1088) 0           block17_6_ac[0][0]               \n",
      "                                                                 block17_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_ac (Activation)       (None, 12, 12, 1088) 0           block17_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 12, 12, 128)  139264      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 12, 12, 128)  384         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 12, 12, 128)  0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 12, 12, 160)  143360      activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 12, 12, 160)  480         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 12, 12, 160)  0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 12, 12, 192)  208896      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 12, 12, 192)  215040      activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 12, 12, 192)  576         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 12, 12, 192)  576         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 12, 12, 192)  0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 12, 12, 192)  0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_104[0][0]             \n",
      "                                                                 activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_8 (Lambda)              (None, 12, 12, 1088) 0           block17_7_ac[0][0]               \n",
      "                                                                 block17_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_ac (Activation)       (None, 12, 12, 1088) 0           block17_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 12, 12, 128)  139264      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 12, 12, 128)  384         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 12, 12, 128)  0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 12, 12, 160)  143360      activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 12, 12, 160)  480         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 12, 12, 160)  0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 12, 12, 192)  208896      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 12, 12, 192)  215040      activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 12, 12, 192)  576         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 12, 12, 192)  576         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 12, 12, 192)  0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 12, 12, 192)  0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_108[0][0]             \n",
      "                                                                 activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_9 (Lambda)              (None, 12, 12, 1088) 0           block17_8_ac[0][0]               \n",
      "                                                                 block17_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_ac (Activation)       (None, 12, 12, 1088) 0           block17_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 12, 12, 128)  139264      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 12, 12, 128)  384         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 12, 12, 128)  0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 12, 12, 160)  143360      activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 12, 12, 160)  480         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 12, 12, 160)  0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 12, 12, 192)  208896      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 12, 12, 192)  215040      activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 12, 12, 192)  576         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 12, 12, 192)  576         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 12, 12, 192)  0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 12, 12, 192)  0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_112[0][0]             \n",
      "                                                                 activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_10 (Lambda)             (None, 12, 12, 1088) 0           block17_9_ac[0][0]               \n",
      "                                                                 block17_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_ac (Activation)      (None, 12, 12, 1088) 0           block17_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 12, 12, 128)  139264      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 12, 12, 128)  384         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 12, 12, 128)  0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 12, 12, 160)  143360      activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 12, 12, 160)  480         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 12, 12, 160)  0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 12, 12, 192)  208896      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 12, 12, 192)  215040      activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 12, 12, 192)  576         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 12, 12, 192)  576         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 12, 12, 192)  0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 12, 12, 192)  0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_116[0][0]             \n",
      "                                                                 activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_11_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_11 (Lambda)             (None, 12, 12, 1088) 0           block17_10_ac[0][0]              \n",
      "                                                                 block17_11_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_ac (Activation)      (None, 12, 12, 1088) 0           block17_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 12, 12, 128)  139264      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 12, 12, 128)  384         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 12, 12, 128)  0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 12, 12, 160)  143360      activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 12, 12, 160)  480         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 12, 12, 160)  0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 12, 12, 192)  208896      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 12, 12, 192)  215040      activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 12, 12, 192)  576         conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 12, 12, 192)  576         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 12, 12, 192)  0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 12, 12, 192)  0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_120[0][0]             \n",
      "                                                                 activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_12_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_12 (Lambda)             (None, 12, 12, 1088) 0           block17_11_ac[0][0]              \n",
      "                                                                 block17_12_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_ac (Activation)      (None, 12, 12, 1088) 0           block17_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 12, 12, 128)  139264      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 12, 12, 128)  384         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 12, 12, 128)  0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 12, 12, 160)  143360      activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 12, 12, 160)  480         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 12, 12, 160)  0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 12, 12, 192)  208896      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 12, 12, 192)  215040      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 12, 12, 192)  576         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 12, 12, 192)  576         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 12, 12, 192)  0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 12, 12, 192)  0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_124[0][0]             \n",
      "                                                                 activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_13_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_13 (Lambda)             (None, 12, 12, 1088) 0           block17_12_ac[0][0]              \n",
      "                                                                 block17_13_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_ac (Activation)      (None, 12, 12, 1088) 0           block17_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 12, 12, 128)  139264      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 12, 12, 128)  384         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 12, 12, 128)  0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 12, 12, 160)  143360      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 12, 12, 160)  480         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 12, 12, 160)  0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 12, 12, 192)  208896      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 12, 12, 192)  215040      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 12, 12, 192)  576         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 12, 12, 192)  576         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 12, 12, 192)  0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 12, 12, 192)  0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_128[0][0]             \n",
      "                                                                 activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_14_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_14 (Lambda)             (None, 12, 12, 1088) 0           block17_13_ac[0][0]              \n",
      "                                                                 block17_14_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_ac (Activation)      (None, 12, 12, 1088) 0           block17_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 12, 12, 128)  139264      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 12, 12, 128)  384         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 12, 12, 128)  0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 12, 12, 160)  143360      activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 12, 12, 160)  480         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 12, 12, 160)  0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 12, 12, 192)  208896      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 12, 12, 192)  215040      activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 12, 12, 192)  576         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 12, 12, 192)  576         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 12, 12, 192)  0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 12, 12, 192)  0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_132[0][0]             \n",
      "                                                                 activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_15_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_15 (Lambda)             (None, 12, 12, 1088) 0           block17_14_ac[0][0]              \n",
      "                                                                 block17_15_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_ac (Activation)      (None, 12, 12, 1088) 0           block17_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 12, 12, 128)  139264      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 12, 12, 128)  384         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 12, 12, 128)  0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 12, 12, 160)  143360      activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 12, 12, 160)  480         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 12, 12, 160)  0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 12, 12, 192)  208896      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 12, 12, 192)  215040      activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 12, 12, 192)  576         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 12, 12, 192)  576         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 12, 12, 192)  0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 12, 12, 192)  0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_136[0][0]             \n",
      "                                                                 activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_16_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_16 (Lambda)             (None, 12, 12, 1088) 0           block17_15_ac[0][0]              \n",
      "                                                                 block17_16_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_ac (Activation)      (None, 12, 12, 1088) 0           block17_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 12, 12, 128)  139264      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 12, 12, 128)  384         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 12, 12, 128)  0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 12, 12, 160)  143360      activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 12, 12, 160)  480         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 12, 12, 160)  0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 12, 12, 192)  208896      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 12, 12, 192)  215040      activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 12, 12, 192)  576         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 12, 12, 192)  576         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 12, 12, 192)  0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 12, 12, 192)  0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_140[0][0]             \n",
      "                                                                 activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_17_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_17 (Lambda)             (None, 12, 12, 1088) 0           block17_16_ac[0][0]              \n",
      "                                                                 block17_17_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_ac (Activation)      (None, 12, 12, 1088) 0           block17_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 12, 12, 128)  139264      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 12, 12, 128)  384         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 12, 12, 128)  0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 12, 12, 160)  143360      activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 12, 12, 160)  480         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 12, 12, 160)  0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 12, 12, 192)  208896      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 12, 12, 192)  215040      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 12, 12, 192)  576         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 12, 12, 192)  576         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 12, 12, 192)  0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 12, 12, 192)  0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_144[0][0]             \n",
      "                                                                 activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_18_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_18 (Lambda)             (None, 12, 12, 1088) 0           block17_17_ac[0][0]              \n",
      "                                                                 block17_18_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_ac (Activation)      (None, 12, 12, 1088) 0           block17_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 12, 12, 128)  139264      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 12, 12, 128)  384         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 12, 12, 128)  0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 12, 12, 160)  143360      activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 12, 12, 160)  480         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 12, 12, 160)  0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 12, 12, 192)  208896      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 12, 12, 192)  215040      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 12, 12, 192)  576         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 12, 12, 192)  576         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 12, 12, 192)  0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 12, 12, 192)  0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_148[0][0]             \n",
      "                                                                 activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_19_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_19 (Lambda)             (None, 12, 12, 1088) 0           block17_18_ac[0][0]              \n",
      "                                                                 block17_19_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_ac (Activation)      (None, 12, 12, 1088) 0           block17_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 12, 12, 128)  139264      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 12, 12, 128)  384         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 12, 12, 128)  0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 12, 12, 160)  143360      activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 12, 12, 160)  480         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 12, 12, 160)  0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 12, 12, 192)  208896      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 12, 12, 192)  215040      activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 12, 12, 192)  576         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 12, 12, 192)  576         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 12, 12, 192)  0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 12, 12, 192)  0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_152[0][0]             \n",
      "                                                                 activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_20_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_20 (Lambda)             (None, 12, 12, 1088) 0           block17_19_ac[0][0]              \n",
      "                                                                 block17_20_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_ac (Activation)      (None, 12, 12, 1088) 0           block17_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 12, 12, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 12, 12, 256)  768         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 12, 12, 256)  0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 12, 12, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 12, 12, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 12, 12, 288)  663552      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 12, 12, 256)  768         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 12, 12, 256)  768         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 12, 12, 288)  864         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 12, 12, 256)  0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 12, 12, 256)  0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 12, 12, 288)  0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 5, 5, 384)    884736      activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 5, 5, 288)    663552      activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 5, 5, 320)    829440      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 5, 5, 384)    1152        conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 5, 5, 288)    864         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 5, 5, 320)    960         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 5, 5, 384)    0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 5, 5, 288)    0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 5, 5, 320)    0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 1088)   0           block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_7a (Concatenate)          (None, 5, 5, 2080)   0           activation_157[0][0]             \n",
      "                                                                 activation_159[0][0]             \n",
      "                                                                 activation_162[0][0]             \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 5, 5, 192)    399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 5, 5, 192)    576         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 5, 5, 192)    0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 5, 5, 224)    129024      activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 5, 5, 224)    672         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 5, 5, 224)    0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 5, 5, 192)    399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 5, 5, 256)    172032      activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 5, 5, 192)    576         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 5, 5, 256)    768         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 5, 5, 192)    0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 5, 5, 256)    0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_163[0][0]             \n",
      "                                                                 activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_1_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1 (Lambda)               (None, 5, 5, 2080)   0           mixed_7a[0][0]                   \n",
      "                                                                 block8_1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_ac (Activation)        (None, 5, 5, 2080)   0           block8_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 5, 5, 192)    399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 5, 5, 192)    576         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 5, 5, 192)    0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 5, 5, 224)    129024      activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 5, 5, 224)    672         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 5, 5, 224)    0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 5, 5, 192)    399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 5, 5, 256)    172032      activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 5, 5, 192)    576         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 5, 5, 256)    768         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 5, 5, 192)    0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 5, 5, 256)    0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_167[0][0]             \n",
      "                                                                 activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_2_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2 (Lambda)               (None, 5, 5, 2080)   0           block8_1_ac[0][0]                \n",
      "                                                                 block8_2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_ac (Activation)        (None, 5, 5, 2080)   0           block8_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 5, 5, 192)    399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 5, 5, 192)    576         conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 5, 5, 192)    0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 5, 5, 224)    129024      activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 5, 5, 224)    672         conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 5, 5, 224)    0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 5, 5, 192)    399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 5, 5, 256)    172032      activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 5, 5, 192)    576         conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 5, 5, 256)    768         conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 5, 5, 192)    0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 5, 5, 256)    0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_171[0][0]             \n",
      "                                                                 activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_3_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3 (Lambda)               (None, 5, 5, 2080)   0           block8_2_ac[0][0]                \n",
      "                                                                 block8_3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_ac (Activation)        (None, 5, 5, 2080)   0           block8_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 5, 5, 192)    399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 5, 5, 192)    576         conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 5, 5, 192)    0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 5, 5, 224)    129024      activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 5, 5, 224)    672         conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 5, 5, 224)    0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 5, 5, 192)    399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 5, 5, 256)    172032      activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 5, 5, 192)    576         conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 5, 5, 256)    768         conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 5, 5, 192)    0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 5, 5, 256)    0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_175[0][0]             \n",
      "                                                                 activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_4_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4 (Lambda)               (None, 5, 5, 2080)   0           block8_3_ac[0][0]                \n",
      "                                                                 block8_4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_ac (Activation)        (None, 5, 5, 2080)   0           block8_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 5, 5, 192)    399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 5, 5, 192)    576         conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 5, 5, 192)    0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 5, 5, 224)    129024      activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 5, 5, 224)    672         conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 5, 5, 224)    0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 5, 5, 192)    399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 5, 5, 256)    172032      activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 5, 5, 192)    576         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 5, 5, 256)    768         conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 5, 5, 192)    0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 5, 5, 256)    0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_179[0][0]             \n",
      "                                                                 activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_5_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5 (Lambda)               (None, 5, 5, 2080)   0           block8_4_ac[0][0]                \n",
      "                                                                 block8_5_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_ac (Activation)        (None, 5, 5, 2080)   0           block8_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 5, 5, 192)    399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 5, 5, 192)    576         conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 5, 5, 192)    0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 5, 5, 224)    129024      activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 5, 5, 224)    672         conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 5, 5, 224)    0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 5, 5, 192)    399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 5, 5, 256)    172032      activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 5, 5, 192)    576         conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 5, 5, 256)    768         conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 5, 5, 192)    0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 5, 5, 256)    0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_183[0][0]             \n",
      "                                                                 activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_6_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6 (Lambda)               (None, 5, 5, 2080)   0           block8_5_ac[0][0]                \n",
      "                                                                 block8_6_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_ac (Activation)        (None, 5, 5, 2080)   0           block8_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 5, 5, 192)    399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 5, 5, 192)    576         conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 5, 5, 192)    0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 5, 5, 224)    129024      activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 5, 5, 224)    672         conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 5, 5, 224)    0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 5, 5, 192)    399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 5, 5, 256)    172032      activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 5, 5, 192)    576         conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 5, 5, 256)    768         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 5, 5, 192)    0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 5, 5, 256)    0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_187[0][0]             \n",
      "                                                                 activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_7_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7 (Lambda)               (None, 5, 5, 2080)   0           block8_6_ac[0][0]                \n",
      "                                                                 block8_7_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_ac (Activation)        (None, 5, 5, 2080)   0           block8_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 5, 5, 192)    399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 5, 5, 192)    576         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 5, 5, 192)    0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 5, 5, 224)    129024      activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 5, 5, 224)    672         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 5, 5, 224)    0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 5, 5, 192)    399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 5, 5, 256)    172032      activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 5, 5, 192)    576         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 5, 5, 256)    768         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 5, 5, 192)    0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 5, 5, 256)    0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_191[0][0]             \n",
      "                                                                 activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_8_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8 (Lambda)               (None, 5, 5, 2080)   0           block8_7_ac[0][0]                \n",
      "                                                                 block8_8_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_ac (Activation)        (None, 5, 5, 2080)   0           block8_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 5, 5, 192)    399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 5, 5, 192)    576         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 5, 5, 192)    0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 5, 5, 224)    129024      activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 5, 5, 224)    672         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 5, 5, 224)    0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 5, 5, 192)    399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 5, 5, 256)    172032      activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 5, 5, 192)    576         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 5, 5, 256)    768         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 5, 5, 192)    0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 5, 5, 256)    0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_195[0][0]             \n",
      "                                                                 activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_9_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_9 (Lambda)               (None, 5, 5, 2080)   0           block8_8_ac[0][0]                \n",
      "                                                                 block8_9_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_ac (Activation)        (None, 5, 5, 2080)   0           block8_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 5, 5, 192)    399360      block8_9_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 5, 5, 192)    576         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 5, 5, 192)    0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 5, 5, 224)    129024      activation_200[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 5, 5, 224)    672         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 5, 5, 224)    0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 5, 5, 192)    399360      block8_9_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 5, 5, 256)    172032      activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 5, 5, 192)    576         conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 5, 5, 256)    768         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 5, 5, 192)    0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 5, 5, 256)    0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_10_mixed (Concatenate)   (None, 5, 5, 448)    0           activation_199[0][0]             \n",
      "                                                                 activation_202[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_10_conv (Conv2D)         (None, 5, 5, 2080)   933920      block8_10_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_10 (Lambda)              (None, 5, 5, 2080)   0           block8_9_ac[0][0]                \n",
      "                                                                 block8_10_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b (Conv2D)                (None, 5, 5, 1536)   3194880     block8_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b_bn (BatchNormalization) (None, 5, 5, 1536)   4608        conv_7b[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b_ac (Activation)         (None, 5, 5, 1536)   0           conv_7b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 38400)        0           conv_7b_ac[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 8)            307208      flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 54,643,944\n",
      "Trainable params: 54,583,400\n",
      "Non-trainable params: 60,544\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15422 samples, validate on 6610 samples\n",
      "Epoch 1/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.4253 - accuracy: 0.8579\n",
      "Epoch 00001: val_loss improved from inf to 0.60549, saving model to D:\\Projects\\ODIR\\ODIRCODE\\bestres\\IncResV2\\my_best_model.epoch001-loss0.61.hdf5\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.87479, saving model to D:\\Projects\\ODIR\\ODIRCODE\\bestres\\IncResV2\\my_best_model.epoch001-acc0.87.hdf5\n",
      "15422/15422 [==============================] - 221s 14ms/sample - loss: 0.4254 - accuracy: 0.8579 - val_loss: 0.6055 - val_accuracy: 0.8748\n",
      "Epoch 2/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.2976 - accuracy: 0.8786\n",
      "Epoch 00002: val_loss did not improve from 0.60549\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.87479\n",
      "15422/15422 [==============================] - 194s 13ms/sample - loss: 0.2978 - accuracy: 0.8786 - val_loss: 2.6215 - val_accuracy: 0.8704\n",
      "Epoch 3/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.3771 - accuracy: 0.8626\n",
      "Epoch 00003: val_loss improved from 0.60549 to 0.29657, saving model to D:\\Projects\\ODIR\\ODIRCODE\\bestres\\IncResV2\\my_best_model.epoch003-loss0.30.hdf5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.87479\n",
      "15422/15422 [==============================] - 195s 13ms/sample - loss: 0.3771 - accuracy: 0.8626 - val_loss: 0.2966 - val_accuracy: 0.8736\n",
      "Epoch 4/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.3237 - accuracy: 0.8653\n",
      "Epoch 00004: val_loss did not improve from 0.29657\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.87479\n",
      "15422/15422 [==============================] - 194s 13ms/sample - loss: 0.3238 - accuracy: 0.8653 - val_loss: 6.1597 - val_accuracy: 0.8554\n",
      "Epoch 5/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.3051 - accuracy: 0.8722\n",
      "Epoch 00005: val_loss did not improve from 0.29657\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.87479\n",
      "15422/15422 [==============================] - 195s 13ms/sample - loss: 0.3051 - accuracy: 0.8722 - val_loss: 51.0757 - val_accuracy: 0.7778\n",
      "Epoch 6/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.2977 - accuracy: 0.8738\n",
      "Epoch 00006: val_loss did not improve from 0.29657\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.87479\n",
      "15422/15422 [==============================] - 193s 13ms/sample - loss: 0.2977 - accuracy: 0.8738 - val_loss: 14.2318 - val_accuracy: 0.8553\n",
      "Epoch 7/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.2816 - accuracy: 0.8796\n",
      "Epoch 00007: val_loss did not improve from 0.29657\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.87479\n",
      "15422/15422 [==============================] - 193s 13ms/sample - loss: 0.2816 - accuracy: 0.8796 - val_loss: 1.5543 - val_accuracy: 0.8682\n",
      "Epoch 8/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.2695 - accuracy: 0.8854\n",
      "Epoch 00008: val_loss did not improve from 0.29657\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.87479 to 0.88374, saving model to D:\\Projects\\ODIR\\ODIRCODE\\bestres\\IncResV2\\my_best_model.epoch008-acc0.88.hdf5\n",
      "15422/15422 [==============================] - 195s 13ms/sample - loss: 0.2694 - accuracy: 0.8854 - val_loss: 3.0582 - val_accuracy: 0.8837\n",
      "Epoch 9/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.2596 - accuracy: 0.8895\n",
      "Epoch 00009: val_loss did not improve from 0.29657\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.88374\n",
      "15422/15422 [==============================] - 193s 13ms/sample - loss: 0.2596 - accuracy: 0.8895 - val_loss: 172.8821 - val_accuracy: 0.8793\n",
      "Epoch 10/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.2471 - accuracy: 0.8953\n",
      "Epoch 00010: val_loss did not improve from 0.29657\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.88374\n",
      "15422/15422 [==============================] - 193s 13ms/sample - loss: 0.2473 - accuracy: 0.8953 - val_loss: 1.1570 - val_accuracy: 0.8521\n",
      "Epoch 11/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.2483 - accuracy: 0.8965\n",
      "Epoch 00011: val_loss did not improve from 0.29657\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.88374\n",
      "15422/15422 [==============================] - 193s 13ms/sample - loss: 0.2483 - accuracy: 0.8965 - val_loss: 13.2892 - val_accuracy: 0.8711\n",
      "Epoch 12/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.2298 - accuracy: 0.9018\n",
      "Epoch 00012: val_loss did not improve from 0.29657\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.88374 to 0.89217, saving model to D:\\Projects\\ODIR\\ODIRCODE\\bestres\\IncResV2\\my_best_model.epoch012-acc0.89.hdf5\n",
      "15422/15422 [==============================] - 195s 13ms/sample - loss: 0.2299 - accuracy: 0.9018 - val_loss: 0.7209 - val_accuracy: 0.8922\n",
      "Epoch 13/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.2339 - accuracy: 0.9016\n",
      "Epoch 00013: val_loss did not improve from 0.29657\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.89217\n",
      "15422/15422 [==============================] - 193s 13ms/sample - loss: 0.2339 - accuracy: 0.9016 - val_loss: 3.1537 - val_accuracy: 0.8404\n",
      "Epoch 14/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.2468 - accuracy: 0.8958\n",
      "Epoch 00014: val_loss did not improve from 0.29657\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.89217\n",
      "15422/15422 [==============================] - 194s 13ms/sample - loss: 0.2468 - accuracy: 0.8958 - val_loss: 41.5928 - val_accuracy: 0.8628\n",
      "Epoch 15/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.2347 - accuracy: 0.9006\n",
      "Epoch 00015: val_loss did not improve from 0.29657\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.89217\n",
      "15422/15422 [==============================] - 193s 13ms/sample - loss: 0.2348 - accuracy: 0.9006 - val_loss: 5.0214 - val_accuracy: 0.8027\n",
      "Epoch 16/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.2667 - accuracy: 0.8869\n",
      "Epoch 00016: val_loss improved from 0.29657 to 0.25996, saving model to D:\\Projects\\ODIR\\ODIRCODE\\bestres\\IncResV2\\my_best_model.epoch016-loss0.26.hdf5\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.89217 to 0.89261, saving model to D:\\Projects\\ODIR\\ODIRCODE\\bestres\\IncResV2\\my_best_model.epoch016-acc0.89.hdf5\n",
      "15422/15422 [==============================] - 197s 13ms/sample - loss: 0.2668 - accuracy: 0.8869 - val_loss: 0.2600 - val_accuracy: 0.8926\n",
      "Epoch 17/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.2415 - accuracy: 0.8972\n",
      "Epoch 00017: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.89261\n",
      "15422/15422 [==============================] - 194s 13ms/sample - loss: 0.2416 - accuracy: 0.8972 - val_loss: 0.3045 - val_accuracy: 0.8849\n",
      "Epoch 18/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.2132 - accuracy: 0.9085\n",
      "Epoch 00018: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.89261\n",
      "15422/15422 [==============================] - 194s 13ms/sample - loss: 0.2133 - accuracy: 0.9085 - val_loss: 0.6545 - val_accuracy: 0.8909\n",
      "Epoch 19/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.2015 - accuracy: 0.9142\n",
      "Epoch 00019: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.89261\n",
      "15422/15422 [==============================] - 194s 13ms/sample - loss: 0.2016 - accuracy: 0.9142 - val_loss: 1.6886 - val_accuracy: 0.8850\n",
      "Epoch 20/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.1893 - accuracy: 0.9196\n",
      "Epoch 00020: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.89261 to 0.89726, saving model to D:\\Projects\\ODIR\\ODIRCODE\\bestres\\IncResV2\\my_best_model.epoch020-acc0.90.hdf5\n",
      "15422/15422 [==============================] - 195s 13ms/sample - loss: 0.1894 - accuracy: 0.9196 - val_loss: 1.0062 - val_accuracy: 0.8973\n",
      "Epoch 21/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.2023 - accuracy: 0.9138\n",
      "Epoch 00021: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.89726\n",
      "15422/15422 [==============================] - 194s 13ms/sample - loss: 0.2023 - accuracy: 0.9138 - val_loss: 3.1801 - val_accuracy: 0.8907\n",
      "Epoch 22/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.1794 - accuracy: 0.9236\n",
      "Epoch 00022: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.89726 to 0.89966, saving model to D:\\Projects\\ODIR\\ODIRCODE\\bestres\\IncResV2\\my_best_model.epoch022-acc0.90.hdf5\n",
      "15422/15422 [==============================] - 195s 13ms/sample - loss: 0.1794 - accuracy: 0.9236 - val_loss: 8.8673 - val_accuracy: 0.8997\n",
      "Epoch 23/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.1635 - accuracy: 0.9306\n",
      "Epoch 00023: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.89966\n",
      "15422/15422 [==============================] - 194s 13ms/sample - loss: 0.1635 - accuracy: 0.9306 - val_loss: 2.1163 - val_accuracy: 0.8921\n",
      "Epoch 24/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.1473 - accuracy: 0.9377\n",
      "Epoch 00024: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.89966\n",
      "15422/15422 [==============================] - 194s 13ms/sample - loss: 0.1474 - accuracy: 0.9377 - val_loss: 9.0602 - val_accuracy: 0.8861\n",
      "Epoch 25/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.1355 - accuracy: 0.9432\n",
      "Epoch 00025: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.89966 to 0.90327, saving model to D:\\Projects\\ODIR\\ODIRCODE\\bestres\\IncResV2\\my_best_model.epoch025-acc0.90.hdf5\n",
      "15422/15422 [==============================] - 195s 13ms/sample - loss: 0.1355 - accuracy: 0.9432 - val_loss: 0.4186 - val_accuracy: 0.9033\n",
      "Epoch 26/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.1257 - accuracy: 0.9475\n",
      "Epoch 00026: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.90327\n",
      "15422/15422 [==============================] - 194s 13ms/sample - loss: 0.1257 - accuracy: 0.9475 - val_loss: 2.2654 - val_accuracy: 0.8992\n",
      "Epoch 27/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.1115 - accuracy: 0.9536\n",
      "Epoch 00027: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.90327\n",
      "15422/15422 [==============================] - 193s 13ms/sample - loss: 0.1115 - accuracy: 0.9536 - val_loss: 2.4383 - val_accuracy: 0.8988\n",
      "Epoch 28/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0962 - accuracy: 0.9608\n",
      "Epoch 00028: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.90327 to 0.90361, saving model to D:\\Projects\\ODIR\\ODIRCODE\\bestres\\IncResV2\\my_best_model.epoch028-acc0.90.hdf5\n",
      "15422/15422 [==============================] - 195s 13ms/sample - loss: 0.0963 - accuracy: 0.9608 - val_loss: 0.8992 - val_accuracy: 0.9036\n",
      "Epoch 29/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0843 - accuracy: 0.9661\n",
      "Epoch 00029: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.90361\n",
      "15422/15422 [==============================] - 193s 13ms/sample - loss: 0.0848 - accuracy: 0.9661 - val_loss: 2.6583 - val_accuracy: 0.8972\n",
      "Epoch 30/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0714 - accuracy: 0.9718\n",
      "Epoch 00030: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.90361\n",
      "15422/15422 [==============================] - 194s 13ms/sample - loss: 0.0716 - accuracy: 0.9718 - val_loss: 101.2926 - val_accuracy: 0.9029\n",
      "Epoch 31/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0654 - accuracy: 0.9747\n",
      "Epoch 00031: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.90361\n",
      "15422/15422 [==============================] - 194s 13ms/sample - loss: 0.0655 - accuracy: 0.9747 - val_loss: 29.6639 - val_accuracy: 0.9016\n",
      "Epoch 32/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0557 - accuracy: 0.9782\n",
      "Epoch 00032: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.90361\n",
      "15422/15422 [==============================] - 194s 13ms/sample - loss: 0.0559 - accuracy: 0.9782 - val_loss: 18.6377 - val_accuracy: 0.8999\n",
      "Epoch 33/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0465 - accuracy: 0.9821\n",
      "Epoch 00033: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.90361\n",
      "15422/15422 [==============================] - 194s 13ms/sample - loss: 0.0467 - accuracy: 0.9821 - val_loss: 7.0619 - val_accuracy: 0.9003\n",
      "Epoch 34/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0503 - accuracy: 0.9814\n",
      "Epoch 00034: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.90361\n",
      "15422/15422 [==============================] - 194s 13ms/sample - loss: 0.0503 - accuracy: 0.9814 - val_loss: 18.1280 - val_accuracy: 0.8856\n",
      "Epoch 35/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0472 - accuracy: 0.9825\n",
      "Epoch 00035: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.90361\n",
      "15422/15422 [==============================] - 194s 13ms/sample - loss: 0.0472 - accuracy: 0.9825 - val_loss: 32.4780 - val_accuracy: 0.8860\n",
      "Epoch 36/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0395 - accuracy: 0.9856\n",
      "Epoch 00036: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.90361\n",
      "15422/15422 [==============================] - 194s 13ms/sample - loss: 0.0396 - accuracy: 0.9856 - val_loss: 6.5845 - val_accuracy: 0.8954\n",
      "Epoch 37/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0675 - accuracy: 0.9743\n",
      "Epoch 00037: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.90361\n",
      "15422/15422 [==============================] - 194s 13ms/sample - loss: 0.0677 - accuracy: 0.9742 - val_loss: 43.9996 - val_accuracy: 0.8950\n",
      "Epoch 38/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0401 - accuracy: 0.9857\n",
      "Epoch 00038: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.90361\n",
      "15422/15422 [==============================] - 194s 13ms/sample - loss: 0.0401 - accuracy: 0.9857 - val_loss: 127.3800 - val_accuracy: 0.8872\n",
      "Epoch 39/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0351 - accuracy: 0.9871\n",
      "Epoch 00039: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.90361\n",
      "15422/15422 [==============================] - 194s 13ms/sample - loss: 0.0351 - accuracy: 0.9871 - val_loss: 1881.5397 - val_accuracy: 0.8646\n",
      "Epoch 40/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0293 - accuracy: 0.9892\n",
      "Epoch 00040: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.90361\n",
      "15422/15422 [==============================] - 194s 13ms/sample - loss: 0.0294 - accuracy: 0.9892 - val_loss: 84.2751 - val_accuracy: 0.8969\n",
      "Epoch 41/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0406 - accuracy: 0.9857\n",
      "Epoch 00041: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00041: val_accuracy improved from 0.90361 to 0.90626, saving model to D:\\Projects\\ODIR\\ODIRCODE\\bestres\\IncResV2\\my_best_model.epoch041-acc0.91.hdf5\n",
      "15422/15422 [==============================] - 195s 13ms/sample - loss: 0.0407 - accuracy: 0.9857 - val_loss: 104.9191 - val_accuracy: 0.9063\n",
      "Epoch 42/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0544 - accuracy: 0.9798\n",
      "Epoch 00042: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.90626\n",
      "15422/15422 [==============================] - 194s 13ms/sample - loss: 0.0545 - accuracy: 0.9798 - val_loss: 83.9511 - val_accuracy: 0.8964\n",
      "Epoch 43/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0350 - accuracy: 0.9872\n",
      "Epoch 00043: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.90626\n",
      "15422/15422 [==============================] - 194s 13ms/sample - loss: 0.0350 - accuracy: 0.9872 - val_loss: 90.3361 - val_accuracy: 0.8965\n",
      "Epoch 44/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0230 - accuracy: 0.9918\n",
      "Epoch 00044: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.90626\n",
      "15422/15422 [==============================] - 194s 13ms/sample - loss: 0.0231 - accuracy: 0.9918 - val_loss: 8574.4127 - val_accuracy: 0.8422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0315 - accuracy: 0.9884\n",
      "Epoch 00045: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.90626\n",
      "15422/15422 [==============================] - 193s 13ms/sample - loss: 0.0316 - accuracy: 0.9884 - val_loss: 10.2431 - val_accuracy: 0.9044\n",
      "Epoch 46/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0193 - accuracy: 0.9930\n",
      "Epoch 00046: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.90626\n",
      "15422/15422 [==============================] - 192s 12ms/sample - loss: 0.0194 - accuracy: 0.9930 - val_loss: 5.5375 - val_accuracy: 0.9044\n",
      "Epoch 47/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0192 - accuracy: 0.9931\n",
      "Epoch 00047: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.90626\n",
      "15422/15422 [==============================] - 192s 12ms/sample - loss: 0.0194 - accuracy: 0.9931 - val_loss: 5.1893 - val_accuracy: 0.8940\n",
      "Epoch 48/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0197 - accuracy: 0.9927\n",
      "Epoch 00048: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.90626\n",
      "15422/15422 [==============================] - 192s 12ms/sample - loss: 0.0197 - accuracy: 0.9927 - val_loss: 4.0709 - val_accuracy: 0.8942\n",
      "Epoch 49/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0186 - accuracy: 0.9932\n",
      "Epoch 00049: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.90626\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0186 - accuracy: 0.9932 - val_loss: 0.5512 - val_accuracy: 0.9062\n",
      "Epoch 50/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0173 - accuracy: 0.9939\n",
      "Epoch 00050: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.90626\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0173 - accuracy: 0.9939 - val_loss: 2.3143 - val_accuracy: 0.9025\n",
      "Epoch 51/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0178 - accuracy: 0.9938\n",
      "Epoch 00051: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.90626\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0178 - accuracy: 0.9938 - val_loss: 4.2719 - val_accuracy: 0.8958\n",
      "Epoch 52/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0162 - accuracy: 0.9942\n",
      "Epoch 00052: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00052: val_accuracy improved from 0.90626 to 0.90876, saving model to D:\\Projects\\ODIR\\ODIRCODE\\bestres\\IncResV2\\my_best_model.epoch052-acc0.91.hdf5\n",
      "15422/15422 [==============================] - 193s 12ms/sample - loss: 0.0163 - accuracy: 0.9941 - val_loss: 0.5125 - val_accuracy: 0.9088\n",
      "Epoch 53/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0255 - accuracy: 0.9908\n",
      "Epoch 00053: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0255 - accuracy: 0.9908 - val_loss: 1.1045 - val_accuracy: 0.9011\n",
      "Epoch 54/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0193 - accuracy: 0.9933\n",
      "Epoch 00054: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0193 - accuracy: 0.9933 - val_loss: 1.1993 - val_accuracy: 0.8961\n",
      "Epoch 55/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0216 - accuracy: 0.9925\n",
      "Epoch 00055: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0218 - accuracy: 0.9925 - val_loss: 0.5538 - val_accuracy: 0.8995\n",
      "Epoch 56/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0172 - accuracy: 0.9940\n",
      "Epoch 00056: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0172 - accuracy: 0.9940 - val_loss: 0.7050 - val_accuracy: 0.9035\n",
      "Epoch 57/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0131 - accuracy: 0.9955\n",
      "Epoch 00057: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0131 - accuracy: 0.9955 - val_loss: 1.6186 - val_accuracy: 0.8875\n",
      "Epoch 58/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0132 - accuracy: 0.9953\n",
      "Epoch 00058: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0132 - accuracy: 0.9953 - val_loss: 0.9179 - val_accuracy: 0.8981\n",
      "Epoch 59/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0124 - accuracy: 0.9958\n",
      "Epoch 00059: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0125 - accuracy: 0.9958 - val_loss: 1.3970 - val_accuracy: 0.9024\n",
      "Epoch 60/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.9940\n",
      "Epoch 00060: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0177 - accuracy: 0.9940 - val_loss: 1.1687 - val_accuracy: 0.9006\n",
      "Epoch 61/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0121 - accuracy: 0.9957\n",
      "Epoch 00061: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 189s 12ms/sample - loss: 0.0122 - accuracy: 0.9957 - val_loss: 0.8526 - val_accuracy: 0.9029\n",
      "Epoch 62/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9953\n",
      "Epoch 00062: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0134 - accuracy: 0.9953 - val_loss: 0.8726 - val_accuracy: 0.9070\n",
      "Epoch 63/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0114 - accuracy: 0.9961\n",
      "Epoch 00063: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0114 - accuracy: 0.9961 - val_loss: 1.9605 - val_accuracy: 0.9037\n",
      "Epoch 64/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0114 - accuracy: 0.9959\n",
      "Epoch 00064: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0114 - accuracy: 0.9959 - val_loss: 2.8387 - val_accuracy: 0.8978\n",
      "Epoch 65/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0117 - accuracy: 0.9961\n",
      "Epoch 00065: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0118 - accuracy: 0.9961 - val_loss: 6.9120 - val_accuracy: 0.9018\n",
      "Epoch 66/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0125 - accuracy: 0.9955\n",
      "Epoch 00066: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0125 - accuracy: 0.9955 - val_loss: 14.1551 - val_accuracy: 0.9068\n",
      "Epoch 67/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0101 - accuracy: 0.9964\n",
      "Epoch 00067: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0101 - accuracy: 0.9964 - val_loss: 2.4236 - val_accuracy: 0.9075\n",
      "Epoch 68/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0106 - accuracy: 0.9961\n",
      "Epoch 00068: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0106 - accuracy: 0.9961 - val_loss: 16.9707 - val_accuracy: 0.9061\n",
      "Epoch 69/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0483 - accuracy: 0.9829\n",
      "Epoch 00069: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0486 - accuracy: 0.9829 - val_loss: 8.6915 - val_accuracy: 0.8950\n",
      "Epoch 70/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0243 - accuracy: 0.9912\n",
      "Epoch 00070: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0243 - accuracy: 0.9912 - val_loss: 3.6071 - val_accuracy: 0.9050\n",
      "Epoch 71/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0145 - accuracy: 0.9949\n",
      "Epoch 00071: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0146 - accuracy: 0.9949 - val_loss: 6.9332 - val_accuracy: 0.9012\n",
      "Epoch 72/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0556 - accuracy: 0.9793\n",
      "Epoch 00072: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0557 - accuracy: 0.9793 - val_loss: 10.7391 - val_accuracy: 0.9022\n",
      "Epoch 73/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0181 - accuracy: 0.9936\n",
      "Epoch 00073: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0181 - accuracy: 0.9936 - val_loss: 24.9785 - val_accuracy: 0.9019\n",
      "Epoch 74/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0125 - accuracy: 0.9958\n",
      "Epoch 00074: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0125 - accuracy: 0.9958 - val_loss: 13.4599 - val_accuracy: 0.9019\n",
      "Epoch 75/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0111 - accuracy: 0.9961\n",
      "Epoch 00075: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0111 - accuracy: 0.9961 - val_loss: 12.8519 - val_accuracy: 0.9022\n",
      "Epoch 76/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0100 - accuracy: 0.9964\n",
      "Epoch 00076: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0101 - accuracy: 0.9964 - val_loss: 7.8803 - val_accuracy: 0.9036\n",
      "Epoch 77/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0119 - accuracy: 0.9960\n",
      "Epoch 00077: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0119 - accuracy: 0.9960 - val_loss: 19.6119 - val_accuracy: 0.9027\n",
      "Epoch 78/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0088 - accuracy: 0.9969\n",
      "Epoch 00078: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0088 - accuracy: 0.9969 - val_loss: 12.4114 - val_accuracy: 0.8909\n",
      "Epoch 79/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0123 - accuracy: 0.9956\n",
      "Epoch 00079: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0123 - accuracy: 0.9956 - val_loss: 216.1834 - val_accuracy: 0.8949\n",
      "Epoch 80/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0089 - accuracy: 0.9968\n",
      "Epoch 00080: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0089 - accuracy: 0.9968 - val_loss: 150.8267 - val_accuracy: 0.9061\n",
      "Epoch 81/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0097 - accuracy: 0.9966\n",
      "Epoch 00081: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0097 - accuracy: 0.9966 - val_loss: 818.8250 - val_accuracy: 0.9036\n",
      "Epoch 82/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.9969\n",
      "Epoch 00082: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0092 - accuracy: 0.9969 - val_loss: 71.1918 - val_accuracy: 0.9056\n",
      "Epoch 83/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0103 - accuracy: 0.9964\n",
      "Epoch 00083: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0103 - accuracy: 0.9964 - val_loss: 94.5471 - val_accuracy: 0.9036\n",
      "Epoch 84/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0077 - accuracy: 0.9975\n",
      "Epoch 00084: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0078 - accuracy: 0.9975 - val_loss: 972.5696 - val_accuracy: 0.8980\n",
      "Epoch 85/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0099 - accuracy: 0.9966\n",
      "Epoch 00085: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0099 - accuracy: 0.9966 - val_loss: 26.1681 - val_accuracy: 0.8957\n",
      "Epoch 86/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0090 - accuracy: 0.9969\n",
      "Epoch 00086: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0090 - accuracy: 0.9969 - val_loss: 26.2021 - val_accuracy: 0.8983\n",
      "Epoch 87/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0218 - accuracy: 0.9928\n",
      "Epoch 00087: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0219 - accuracy: 0.9928 - val_loss: 55.6926 - val_accuracy: 0.8908\n",
      "Epoch 88/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0127 - accuracy: 0.9959\n",
      "Epoch 00088: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0127 - accuracy: 0.9959 - val_loss: 25.3015 - val_accuracy: 0.8967\n",
      "Epoch 89/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0077 - accuracy: 0.9974\n",
      "Epoch 00089: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0077 - accuracy: 0.9974 - val_loss: 26.0191 - val_accuracy: 0.8998\n",
      "Epoch 90/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9978\n",
      "Epoch 00090: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0064 - accuracy: 0.9978 - val_loss: 29.4237 - val_accuracy: 0.8977\n",
      "Epoch 91/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9976\n",
      "Epoch 00091: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0073 - accuracy: 0.9976 - val_loss: 22.2151 - val_accuracy: 0.9002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0076 - accuracy: 0.9973\n",
      "Epoch 00092: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0081 - accuracy: 0.9973 - val_loss: 12.8742 - val_accuracy: 0.8962\n",
      "Epoch 93/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0081 - accuracy: 0.9972\n",
      "Epoch 00093: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0081 - accuracy: 0.9972 - val_loss: 13.7275 - val_accuracy: 0.9008\n",
      "Epoch 94/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.9976\n",
      "Epoch 00094: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0067 - accuracy: 0.9976 - val_loss: 8.7962 - val_accuracy: 0.9009\n",
      "Epoch 95/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9976\n",
      "Epoch 00095: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0066 - accuracy: 0.9976 - val_loss: 12.2519 - val_accuracy: 0.8932\n",
      "Epoch 96/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0090 - accuracy: 0.9969\n",
      "Epoch 00096: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0091 - accuracy: 0.9969 - val_loss: 7.3457 - val_accuracy: 0.9075\n",
      "Epoch 97/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0085 - accuracy: 0.9968\n",
      "Epoch 00097: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0085 - accuracy: 0.9968 - val_loss: 10.2768 - val_accuracy: 0.9061\n",
      "Epoch 98/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9980\n",
      "Epoch 00098: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0058 - accuracy: 0.9980 - val_loss: 2.2911 - val_accuracy: 0.9010\n",
      "Epoch 99/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 0.9975\n",
      "Epoch 00099: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0075 - accuracy: 0.9975 - val_loss: 3.6812 - val_accuracy: 0.9057\n",
      "Epoch 100/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0082 - accuracy: 0.9972\n",
      "Epoch 00100: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0084 - accuracy: 0.9971 - val_loss: 29.0698 - val_accuracy: 0.8910\n",
      "Epoch 101/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0096 - accuracy: 0.9966\n",
      "Epoch 00101: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00101: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0096 - accuracy: 0.9966 - val_loss: 5.4762 - val_accuracy: 0.9013\n",
      "Epoch 102/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9987\n",
      "Epoch 00102: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00102: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0036 - accuracy: 0.9987 - val_loss: 4.4778 - val_accuracy: 0.8918\n",
      "Epoch 103/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9981\n",
      "Epoch 00103: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00103: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0057 - accuracy: 0.9981 - val_loss: 4.4533 - val_accuracy: 0.9028\n",
      "Epoch 104/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9976\n",
      "Epoch 00104: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00104: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0073 - accuracy: 0.9976 - val_loss: 12.9303 - val_accuracy: 0.8961\n",
      "Epoch 105/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0076 - accuracy: 0.9972\n",
      "Epoch 00105: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00105: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0077 - accuracy: 0.9972 - val_loss: 5.1393 - val_accuracy: 0.9005\n",
      "Epoch 106/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9982\n",
      "Epoch 00106: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00106: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0054 - accuracy: 0.9982 - val_loss: 4.6700 - val_accuracy: 0.9006\n",
      "Epoch 107/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9980\n",
      "Epoch 00107: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00107: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0065 - accuracy: 0.9980 - val_loss: 11.7500 - val_accuracy: 0.9003\n",
      "Epoch 108/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0070 - accuracy: 0.9975\n",
      "Epoch 00108: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00108: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0070 - accuracy: 0.9975 - val_loss: 13.8241 - val_accuracy: 0.9049\n",
      "Epoch 109/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.9981\n",
      "Epoch 00109: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00109: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0055 - accuracy: 0.9981 - val_loss: 13.3366 - val_accuracy: 0.9041\n",
      "Epoch 110/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9978\n",
      "Epoch 00110: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00110: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0065 - accuracy: 0.9978 - val_loss: 6.5760 - val_accuracy: 0.9050\n",
      "Epoch 111/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0072 - accuracy: 0.9974\n",
      "Epoch 00111: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00111: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0072 - accuracy: 0.9974 - val_loss: 35.7647 - val_accuracy: 0.9011\n",
      "Epoch 112/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9984\n",
      "Epoch 00112: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00112: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0048 - accuracy: 0.9984 - val_loss: 29.6590 - val_accuracy: 0.9017\n",
      "Epoch 113/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0070 - accuracy: 0.9977\n",
      "Epoch 00113: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00113: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0070 - accuracy: 0.9977 - val_loss: 18.0348 - val_accuracy: 0.8986\n",
      "Epoch 114/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9980\n",
      "Epoch 00114: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00114: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0059 - accuracy: 0.9980 - val_loss: 19.4549 - val_accuracy: 0.8967\n",
      "Epoch 115/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9979\n",
      "Epoch 00115: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00115: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0060 - accuracy: 0.9979 - val_loss: 48.0102 - val_accuracy: 0.8983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0077 - accuracy: 0.9976\n",
      "Epoch 00116: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00116: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0077 - accuracy: 0.9976 - val_loss: 126.2201 - val_accuracy: 0.8998\n",
      "Epoch 117/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9986\n",
      "Epoch 00117: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00117: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0041 - accuracy: 0.9986 - val_loss: 40.8459 - val_accuracy: 0.9052\n",
      "Epoch 118/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9979\n",
      "Epoch 00118: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00118: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0063 - accuracy: 0.9979 - val_loss: 19.3058 - val_accuracy: 0.9042\n",
      "Epoch 119/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9983\n",
      "Epoch 00119: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00119: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0048 - accuracy: 0.9983 - val_loss: 69.6814 - val_accuracy: 0.9036\n",
      "Epoch 120/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9981\n",
      "Epoch 00120: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00120: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0058 - accuracy: 0.9981 - val_loss: 1.9934 - val_accuracy: 0.9069\n",
      "Epoch 121/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9977\n",
      "Epoch 00121: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00121: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0073 - accuracy: 0.9977 - val_loss: 15.6028 - val_accuracy: 0.9006\n",
      "Epoch 122/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9983\n",
      "Epoch 00122: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00122: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0051 - accuracy: 0.9983 - val_loss: 13.7157 - val_accuracy: 0.9064\n",
      "Epoch 123/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9982\n",
      "Epoch 00123: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00123: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0052 - accuracy: 0.9982 - val_loss: 2.1522 - val_accuracy: 0.9019\n",
      "Epoch 124/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.9979\n",
      "Epoch 00124: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00124: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0063 - accuracy: 0.9979 - val_loss: 18.3572 - val_accuracy: 0.8986\n",
      "Epoch 125/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9983\n",
      "Epoch 00125: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00125: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0051 - accuracy: 0.9983 - val_loss: 7.6261 - val_accuracy: 0.8969\n",
      "Epoch 126/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9982\n",
      "Epoch 00126: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00126: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0053 - accuracy: 0.9982 - val_loss: 10.9347 - val_accuracy: 0.9053\n",
      "Epoch 127/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9978\n",
      "Epoch 00127: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00127: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0064 - accuracy: 0.9978 - val_loss: 3.1600 - val_accuracy: 0.9035\n",
      "Epoch 128/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.9980\n",
      "Epoch 00128: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00128: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0055 - accuracy: 0.9980 - val_loss: 5.5751 - val_accuracy: 0.8981\n",
      "Epoch 129/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9983\n",
      "Epoch 00129: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00129: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0052 - accuracy: 0.9983 - val_loss: 7.5034 - val_accuracy: 0.9021\n",
      "Epoch 130/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9981\n",
      "Epoch 00130: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00130: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0055 - accuracy: 0.9981 - val_loss: 7.6450 - val_accuracy: 0.8950\n",
      "Epoch 131/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9982\n",
      "Epoch 00131: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00131: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0053 - accuracy: 0.9982 - val_loss: 6.0300 - val_accuracy: 0.9020\n",
      "Epoch 132/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.9976\n",
      "Epoch 00132: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00132: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0067 - accuracy: 0.9976 - val_loss: 19.1744 - val_accuracy: 0.9009\n",
      "Epoch 133/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9985\n",
      "Epoch 00133: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00133: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0042 - accuracy: 0.9985 - val_loss: 22.9816 - val_accuracy: 0.8889\n",
      "Epoch 134/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9979\n",
      "Epoch 00134: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00134: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0062 - accuracy: 0.9979 - val_loss: 96.3957 - val_accuracy: 0.9047\n",
      "Epoch 135/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9990\n",
      "Epoch 00135: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00135: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0030 - accuracy: 0.9989 - val_loss: 24.4179 - val_accuracy: 0.9047\n",
      "Epoch 136/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9985\n",
      "Epoch 00136: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00136: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0049 - accuracy: 0.9985 - val_loss: 16.3874 - val_accuracy: 0.9016\n",
      "Epoch 137/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9986\n",
      "Epoch 00137: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00137: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0043 - accuracy: 0.9986 - val_loss: 38.4168 - val_accuracy: 0.8986\n",
      "Epoch 138/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9982\n",
      "Epoch 00138: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00138: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0057 - accuracy: 0.9982 - val_loss: 114.7477 - val_accuracy: 0.9021\n",
      "Epoch 139/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9988\n",
      "Epoch 00139: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00139: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0038 - accuracy: 0.9988 - val_loss: 47.4547 - val_accuracy: 0.9047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9985\n",
      "Epoch 00140: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00140: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0048 - accuracy: 0.9985 - val_loss: 283.1351 - val_accuracy: 0.9018\n",
      "Epoch 141/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9982\n",
      "Epoch 00141: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00141: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0053 - accuracy: 0.9982 - val_loss: 16.2823 - val_accuracy: 0.9012\n",
      "Epoch 142/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9987\n",
      "Epoch 00142: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00142: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0038 - accuracy: 0.9987 - val_loss: 16.8580 - val_accuracy: 0.9003\n",
      "Epoch 143/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9981\n",
      "Epoch 00143: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00143: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0060 - accuracy: 0.9981 - val_loss: 13.1058 - val_accuracy: 0.9064\n",
      "Epoch 144/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9986\n",
      "Epoch 00144: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00144: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0042 - accuracy: 0.9986 - val_loss: 40.2481 - val_accuracy: 0.9030\n",
      "Epoch 145/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9985\n",
      "Epoch 00145: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00145: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0046 - accuracy: 0.9985 - val_loss: 61.6281 - val_accuracy: 0.8975\n",
      "Epoch 146/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9986\n",
      "Epoch 00146: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00146: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0043 - accuracy: 0.9986 - val_loss: 25.0559 - val_accuracy: 0.9019\n",
      "Epoch 147/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9982\n",
      "Epoch 00147: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00147: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0052 - accuracy: 0.9982 - val_loss: 23.8580 - val_accuracy: 0.9027\n",
      "Epoch 148/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9984\n",
      "Epoch 00148: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00148: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.7583 - val_accuracy: 0.9028\n",
      "Epoch 149/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9988\n",
      "Epoch 00149: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00149: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0038 - accuracy: 0.9988 - val_loss: 49.6597 - val_accuracy: 0.8965\n",
      "Epoch 150/150\n",
      "15420/15422 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9982\n",
      "Epoch 00150: val_loss did not improve from 0.25996\n",
      "\n",
      "Epoch 00150: val_accuracy did not improve from 0.90876\n",
      "15422/15422 [==============================] - 191s 12ms/sample - loss: 0.0054 - accuracy: 0.9982 - val_loss: 66.5004 - val_accuracy: 0.9042\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "#Binary cross entropy of each label. So no really a binary classification problem but\n",
    "#Calculating binary cross entropy for each label. \n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=150,callbacks=callbacks, validation_data=(X_test, y_test), batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c65398d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "plt.plot(epochs, acc, 'y', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a01b374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n",
      "accuracy: 99.05%\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# MLP for Pima Indians Dataset saved to single file\n",
    "from numpy import loadtxt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "model.save(r\"D:\\Projects\\ODIR\\ODIRCODE\\IncResV2\\modelke.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_train, y_train, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "# save model and architecture to single file\n",
    "model.save(r\"D:\\Projects\\ODIR\\ODIRCODE\\IncResV2\\ke2model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "400196ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "# equivalent to: model.save(\"model.h5\")\n",
    "from tensorflow.keras.models import save_model\n",
    "save_model(model, r\"D:\\Projects\\ODIR\\ODIRCODE\\IncResV2\\model2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1351425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 99.05%\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy\n",
    "import os\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_train, y_train, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    " \n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(r\"D:\\Projects\\ODIR\\ODIRCODE\\IncResV2\\model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(r\"D:\\Projects\\ODIR\\ODIRCODE\\IncResV2\\modeljs.h5\")\n",
    "print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1072bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential, model_from_yaml\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy\n",
    "import os\n",
    "\n",
    "# serialize model to YAML\n",
    "model_yaml = model.to_yaml()\n",
    "with open(r\"D:\\Projects\\ODIR\\ODIRCODE\\IncResV2\\model.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(r\"D:\\Projects\\ODIR\\ODIRCODE\\IncResV2\\modelya.h5\")\n",
    "print(\"Saved model to disk\")\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0893c799",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpuodir",
   "language": "python",
   "name": "gpuodir"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
